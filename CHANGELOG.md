# Changelog

## [1.2.0] â€” 2026-02-14

### ðŸ”§ External Config + Reliability Improvements

#### Config-Driven Architecture
- **New: `freerouter.config.json`** â€” all providers, tiers, boundaries, thinking, and auth are now configurable without editing source code
- **New: `src/config.ts`** â€” config loader with file search priority: `FREEROUTER_CONFIG` env â†’ `./freerouter.config.json` â†’ `~/.config/freerouter/config.json`
- Deep-merges file config over built-in defaults â€” fully backward compatible (works without config file)
- New `/config` endpoint â€” view current config with secrets redacted
- New `/reload-config` endpoint â€” reload config without restarting the proxy
- Auth types: `openclaw` (reads auth-profiles.json), `env` (environment variables), per-provider overrides

#### Reliability
- **Request timeouts** â€” `AbortSignal.timeout()` per tier: SIMPLE 30s, MEDIUM 60s, COMPLEX/REASONING 120s
- **Streaming stall detection** â€” aborts if no data received for 30s mid-stream
- **Auto-fallback on timeout** â€” if primary model times out, fallback model is tried automatically
- **Timeout counter** â€” visible in `/health` and `/stats` responses
- **`TimeoutError` class** â€” clean error identification for fallback logic

#### Smarter Classification
- **Token estimation fix** â€” complexity scoring now uses user prompt length only (not system+user). Long system prompts (AGENTS.md, SOUL.md) no longer inflate complexity scores. A "hello" with a 40K system prompt correctly routes to SIMPLE, not COMPLEX
- **Structured output fix** â€” detection now checks user prompt only. System prompts mentioning "json" no longer force tier upgrades
- Total token count still used for context window checks (large input â†’ force COMPLEX)

#### Provider Configuration
- Providers defined in config with `baseUrl`, `api` type (`"anthropic"` or `"openai"`), optional `headers`
- Any OpenAI-compatible provider works out of the box â€” just add baseUrl + API key
- Anthropic gets automatic format translation (tool calls, streaming, thinking)
- Thinking config is now data-driven: specify which models support adaptive thinking and budget amounts

### Migration
No action needed â€” if no `freerouter.config.json` exists, all previous defaults apply. To customize:

```bash
cp freerouter.config.json ~/.config/freerouter/config.json
# Edit providers, tiers, boundaries to taste
curl http://localhost:18800/reload-config  # Apply without restart
```

---

## [1.0.0] â€” 2026-02-14

### ðŸš€ First Full Release â€” Proxy Server + Smart Routing

The first complete release of FreeRouter: a self-hosted, OpenAI-compatible proxy that classifies requests by complexity and routes them to the best model using your own API keys.

### Added

- **Proxy server** (`src/server.ts`) â€” zero-dependency HTTP server exposing OpenAI-compatible `/v1/chat/completions` endpoint
- **Provider translation** (`src/provider.ts`) â€” translates between Anthropic Messages API and OpenAI format:
  - `content_block` / `tool_use` â†’ OpenAI `tool_calls` / `function` format
  - Streaming `input_json_delta` â†’ streamed `arguments` chunks
  - Thinking block filtering (no XML/thinking leak to clients)
  - Non-streaming tool call support with proper `finish_reason: "tool_calls"`
- **Auth module** (`src/auth.ts`) â€” reads OpenClaw's `auth-profiles.json` for API keys
  - Supports Anthropic OAuth tokens (`sk-ant-oat*`) with Claude Code identity headers
  - Supports standard API keys for any provider
- **Logger** (`src/logger.ts`) â€” minimal, zero-dep request logging with configurable levels
- **Model definitions** (`src/models.ts`) â€” model catalog with pricing for cost estimation
- **14-dimension weighted classifier** (`src/router/`) â€” scores requests across:
  - Token count, code presence, reasoning markers, technical terms, creative markers
  - Simple indicators, multi-step patterns, question complexity, imperative verbs
  - Constraint count, output format, reference complexity, negation, domain specificity
  - Agentic task detection (auto-switches to agentic tier configs)
- **Tier-based routing**:
  - SIMPLE â†’ Kimi K2.5 (near-zero cost)
  - MEDIUM â†’ Claude Sonnet 4.5 (balanced)
  - COMPLEX â†’ Claude Opus 4.6 (powerful)
  - REASONING â†’ Claude Opus 4.6 (max thinking)
- **Fallback chains** â€” automatic retry with fallback model on failure
- **Adaptive thinking** â€” auto-configures thinking per model:
  - Sonnet: `{ type: "enabled", budget_tokens: 4096 }`
  - Opus: `{ type: "adaptive" }`
- **Context-aware classification** â€” includes last 3 conversation messages in scoring
- **Multilingual keyword support** â€” English, Chinese, Japanese, Russian, German
- **Test suites** â€” 70/70 tests passing:
  - `tests/test-proxy.sh` â€” 33 core tests (health, validation, routing, streaming, tools, concurrency)
  - `tests/test-proxy-extended.sh` â€” 37 extended tests (unicode, edge cases, stress, alternate endpoints)
- **Management endpoints**: `/health`, `/stats`, `/reload`, `/v1/models`
- **CORS support** for browser-based clients
- **Zero external dependencies** â€” only TypeScript + @types/node as dev deps

### Architecture

```
Client (OpenAI format) â†’ FreeRouter (:18800) â†’ 14-dim Classifier â†’ Route to best model
                                                                     â”œâ”€â”€ Simple â†’ Kimi K2.5
                                                                     â”œâ”€â”€ Medium â†’ Sonnet 4.5
                                                                     â”œâ”€â”€ Complex â†’ Opus 4.6
                                                                     â””â”€â”€ Reasoning â†’ Opus 4.6
```

### Credits

Forked from [BlockRunAI/ClawRouter](https://github.com/BlockRunAI/ClawRouter) (MIT License). Routing engine preserved; x402 payment protocol removed entirely.
